\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage[colorlinks=true]{hyperref}
\usepackage{url}
\usepackage{graphicx}



\title{Color Detection Under Supervised Learning}

\author{
Cyrus Anderson \\
University of Michigan \\
\texttt{andersct@umich.edu} \\
\And
Jocelyn Bohr \\
University of Michigan \\
\texttt{bjocelyn@umich.edu} \\
\AND
Michael Lu \\
University of Michigan \\
\texttt{lumike@umich.edu} \\
\And
Nghia Vo \\
University of Michigan \\
\texttt{thnghia@umich.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

\begin{abstract}
In this report, we apply what we have learned in class and present multiple approaches to a common problem: color classification. There are a vast set of approaches that have been made for this problem, from the simple k-nearest neighbors to machine learning SVM. Under various scenarios, some solutions may perform better than others depending on the specific application and its constraints. Here, our objective is to classify color of the buoys on the surface of a lake during an autonomous robotic boat challenge, under variations such as time of day and different weather and lighting conditions. We want the autonomous robotic boat to use our classifier to make decisions during the challenge. This report will compare results from basic non-learning algorithms such as majority-voting and average color, with more sophisticated learning algorithms such as Naive Bayes and multiclass SVM. 
\end{abstract}

\section{Introduction}
Each summer, the autonomous robotic boat team UM:Autonomy at the University of Michigan competes in the Association for Unmanned Vehicle Systems International's RoboBoat competition held in Virginia Beach, Virginia against various other robotics labs and clubs. Since a pond serves as the site for the various challenges used to judge the robots, buoys act as the primary landmarks. However there are often a few other objects used as landmarks. Buoys often serve as the source of loop closures in the robot's long term path planning, allowing the robot to build an accurate internal map and minimize drift in its state. %'its'
Knowing additional features such as color can reduce contradictory information that produce incorrect mapping. Buoys also serve as boundaries or goals for certain challenges. %[competition specs] 
For example, some challenges involve determining the buoy color. Thus there is substantial need to accurately identify buoy color.
\\\\Currently, the UM:Autonomy robotic boat relies on color filters to determine color. The process involves specifying bounds in RGB values for each color of buoy, then classifying buoys according to their match with the closest color template. These filters are faulty because the tuning is highly susceptible to bias on current lighting conditions, which results in detections that work well for several hours before deteriorating in accuracy. This is especially apparent in Virginia where the sun will be high in the sky (casting glare on the buoys and water) for most of the day with the occasional cloud passing in front to cast a shadow on the entire competition ground. Rainy and overcast days present another set of lighting conditions. Even on days when the sun stays high in the sky, backlit green buoys can appear black \textit{(fig.1 left)}, yellow can appear green, and washed out red may look orange. Additionally, white and black are difficult to filter since the filters that filter these colors generally have high false positive rates and end up including the very light or very dark patches of water produced with the 
noon sun's lighting \textit{(fig.1 right)}.
\\\\In this paper, we examine the results of various supervised learning techniques applied to classifying buoy color, aim to create a procedure to accurately classify buoy colors in a variety of lighting conditions, and creating a robust system that runs faster than the cameras' frame rate of 10Hz while leaving sufficient resources for the boat's other processes.


\begin{figure}[h]
\begin{center}
%\framebox[4.0in]{$\;$}
\fbox{\rule[0cm]{0cm}{0cm} \includegraphics[scale=0.2]{difficult_green}
\includegraphics[scale=0.2]{difficult_black}
 \rule[0cm]{0cm}{0cm}}
\end{center}
\caption{Difficult buoys}
\end{figure}


\section{Proposed Method}

\subsection{Preprocessing}
The robotic boat has two Point Grey Flea 2, 1.3 MP %necessary to include the camera type?
cameras that publish images over the robot's Lightweight 
Communications and Marshalling (LCM) framework at 10 Hz. Logging utilities use LCM to capture and store the various messages, and the datasets are crafted from the different logs of the robot's runs. We label each boat photo by hand: marking the color and rectangle around each buoy within about 30 feet from the boat. From each rectangle, we extract the associated color histogram into a $256 \times 256 \times 256$ feature vector; each entry represents the frequency of the RGB color associated with the entry index. We then reduce this feature vector to a vector of size $64 \times 64 \times 64$, to make feature vectors less sparse and to decrease the classification time (since we are building this for a real time application).

\begin{figure}[h]
\begin{center}
%\framebox[4.0in]{$\;$}
\fbox{\rule[0cm]{0cm}{0cm} \includegraphics[scale=0.2]{labelling} \rule[0cm]{0cm}{0cm}}
\end{center}
\caption{Labelled photo from boat}
\end{figure}

\subsection{Classification}
In this project, we run our training data with multiclass SVM and multinomial Naive Bayes, and have excellent results. \\\\ %passive voice pls
We began with SVM because it is a parametric algorithm, we do not need to store entire 
training data set to make predictions on the boat. It is also kernelized, which provides us with the flexibility to
create arbitrarily complex boundaries. SVM prediction can be used to calculate confidence values for the
decision by taking the distance from the separating hyperplane, which is a useful measurement. SVM does not make any assumptions about the underlying distribution of the data. SVM is a very popular algorithm, so it is very good as a baseline classification algorithm. We used LIBLINEAR for our SVM classification, which utilizes a one-vs-rest multi-class classification scheme [1]. We achieved very good results with LIBLINEAR, as described later, so we decided not to use any kind of SVM kernelization. Using a linear kernel with SVM is preferrable, as it is faster to train and test. Making decisions quickly is essential to this application, as we want to classify colors at the same rate photos are captured (10 Hz).\\\\
We also used Naive Bayes because it is simple to implement, and performs well even on small sets of training data. Like SVM, Naive Bayes is parametric, so we do not need to store the entire training data set to make decisions during the real time application. A parametric classifier is essential, as it is impractical to store all training data on the boat to make decisions in real time. Naive Bayes is also very fast in training and testing, which is ideal for this application. The multinomial Naive Bayes classifier works well for classification with discrete features, such as color frequencies of pixels in a certain section of a photo, or word frequencies of a text document (the classic application). We used MATLAB's multinomial Naive Bayes classifier, which performs very well, as described later.

\section{Related Work}
We want to compare results from the machine learning algorithms to results from non learning algorithms. This isn't a widespread problem many people are trying to solve, so we could not find specific "state-of-the-art" algorithms, thus we implemented two algorithms we thought made sense in this application, majority vote and average vote.

\subsection{Majority vote}
Begin by iterating over the feature vector (described earlier in preprocessing), and choose the index with the highest count. Then compute the RGB vector by converting the index in the feature vector to the index in the original histogram, and store this as the most popular color. Compute the Euclidian distance between this RGB vector and the RGB vectors of our 6 colors, and classify the associated buoy as the color which yields the smallest distance.\\
The result was not as high as we expected, as a lot of the non-black buoys were classified as black because the shadow and water surface included in the picture popularized the count of black/near-black colors in the feature vector. In our 130-size test data, we get an average accuracy of ~21\% over.

\subsection{Average vote}
Begin by iterating over all the RGB values, construct an RGB vector representing the total weighted sum of the RGB counts in the feature vector. Then find the average RGB value by dividingby the total counts in the feature vector. Compute the Euclideian distance between this RGB vector and the RGB vectore of our 6 colors, and classify the associated buoy as the color which yields the smallest distance.\\
This result was much better than the majority vote algorithm, but still far from good. This can again be attributed to the mixture of color in the picture boxes. In our 130-size test data, we get an average accuract of ~48\%.

// cyrus other related work

Color histograms have been in use for some time since their introduction [4] and are popular to due their invariance to translation and rotation in viewing perspective, and robustness under changes in viewing angle and scale. Their low computational complexity makes them ideal for fast paced environments unsuitable for many more complex color detection techniques from computer vision, and they have found a usage in robotic soccer [newlink1] and other realtime applications [newlink2, newlink3]. A different approach is color constancy, which considers the color of the light source with that of the object to determine the object's color under a canonical light source from which a classification can be made. A standard approach in an unconstrained environment is to estimate parameters of the light source and then compute the object's illumination invariant descriptor under the canonical light source [1, 2]. Since early formulations of color constancy algorithms [newlink4], more recent versions have reduced complexity to that of a FFT [newlink5]. 

\section{Experimental Results}
Using both linear SVM and multinomial Naive Bayes, we achieve excellent accuracy rates, especially compared to current methods discussed in related works. With enough training examples, both methods achieve over 98\% accuracy. Naive Bayes performs marginally better, the advantage of Naive Bayes is emphasized when fewer training examples are used. Each average accuracy is calculated by selecting a random training set of size $n$, then selecting a random testing set of size 130 from the remaining data, then train and test classifiers accordingly. The average accuracy is taken over 10 classification results. Although these results are excellent, we believe one contributing factor to such great results can be attributed to a fairly homogeneous data set. We do not have enough variation in our data set, so classification is easier. This problem, and how we intend to solve it, will be discussed in the future milestones section. Experimental results are shown below.

\begin{table}[hp]
\caption{Linear SVM Average Accuracy}
\begin{center}
\begin{tabular}{c|c}
{\bf EXAMPLES}  &{\bf ACCURACY}
\\ \hline
50              &89.08 \\
100             &93.77 \\
200             &96.92 \\
400             &97.85 \\
700             &98.38 \\
\end{tabular}
\end{center}
\end{table}

\begin{table}[hp]
\caption{Multinomial Naive Bayes Average Accuracy}
\begin{center}
\begin{tabular}{c|c}
{\bf EXAMPLES}  &{\bf ACCURACY}
\\ \hline 
50              &92.85 \\
100             &96.54 \\
200             &97.31 \\
400             &98.38 \\
700             &98.31 \\
\end{tabular}
\end{center}
\end{table}

\section{Future Milestones}
One problem with our method we have identified is that the data set we are using is from one log, resulting in a very homogenous data set. Within one week from the due date of the progress report, we plan to label at least another 1000-5000 buoys, including many more blue and green buoys, and more buoys in varied lighting conditions. We hope that after running our algorithms on this data set with variation, we have a more realistic classification accuracy, which will perform better during the real application. We also want to try to add a feature which encodes the direction of lighting, to be completed within two weeks. One idea we have as an extension to this color classification project is implementing a segmentation algorithm to identify buoy boundaries under unsupervised learning, then do color classification with or current supervised learning algorithms. We are considering an extension to this project as we have achieved excellent results so far, thus we don't have much room for further improvement for the rest of the semester. We will discuss what we should pursue as a possible extension with the EECS445 staff. 
 

\section{Conclusion}

% // michael do conclusion [done]
Our group's aim is to correctly detect the colors of buoys in pictures. %importance here
So far, we have only trained and tested using multiclass SVM and multinomial Naive Bayes. As of now, the results have been accurate. We surmise that this accuracy results from our overlapping data. The majority of our data overlaps because we obtained our data from a single recording log.  Next, we aim to obtain a less homogenous data set by retrieving more data from other recording logs and performing error analysis with the new data. We are also aiming to add a feature that accounts the direction of lighting by the sun.

\subsubsection*{References}

%// michael do references
%done

%References follow the acknowledgments. Use unnumbered third level heading for
%the references. Any choice of citation style is acceptable as long as you are
%consistent. It is permissible to reduce the font size to `small' (9-point) 
%when listing the references. {\bf Remember that this year you can use
%a ninth page as long as it contains \emph{only} cited references.}

\small{
[1]  Agarwal V., Abidi B.R., Koschan A., \& Abidi M.A. (2006). An Overview of Color Constancy Algorithm, {\it Journal of Pattern Recognition Research}, 1(1), 42-54

[2] Forsyth, D.A. (1990). A Novel Algorithm for Colour Constancy, {\it International Journal of Computer Vision}, 5(1), 5-36

[3]  7th RoboBoat Competition - Final Rules (2014). Retrieved from
\url{https://higherlogicdownload.s3.amazonaws.com/AUVSI/fb9a8da0-2ac8-42d1-a11e-d58c1e158347/UploadedFiles/RoboBoat_2014_final_rules.pdf}

[4] Swain, M. J. \& Ballard, D. H. (1991). Color Indexing, {\it International Journal of Computer Vision}, 7(1),11-32

%[1] Alexander, J.A. \& Mozer, M.C. (1995) Template-based algorithms
%for connectionist rule extraction. In G. Tesauro, D. S. Touretzky
%and T.K. Leen (eds.), {\it Advances in Neural Information Processing
%Systems 7}, pp. 609-616. Cambridge, MA: MIT Press.

%[2] Bower, J.M. \& Beeman, D. (1995) {\it The Book of GENESIS: Exploring
%Realistic Neural Models with the GEneral NEural SImulation System.}
%New York: TELOS/Springer-Verlag.

%[3] Hasselmo, M.E., Schnell, E. \& Barkai, E. (1995) Dynamics of learning
%and recall at excitatory recurrent synapses and cholinergic modulation
%in rat hippocampal region CA3. {\it Journal of Neuroscience}
%{\bf 15}(7):5249-5262.
}

\end{document}
